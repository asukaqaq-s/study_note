
- 虚拟地址和物理地址
- 分页机制和分段机制
- 地址翻译：tlb、页表项
- OS 管理页表：使能、分配、维护
- 扩展功能：共享内存、写时拷贝、大页机制


## 1. 虚拟地址和物理地址

现代 OS 中为应用程序提供虚拟内存抽象，在应用进程的角度来看，他独享整个内核和CPU。每个进程有自己独立的虚拟内存空间，无法直接访问其他进程的内存。为此应用程序读写使用的地址都是虚拟地址，比如我们常见的指针。

然而，应用程序的数据和代码会被操作系统加载到物理内存，访问物理内存实际上只能使用物理地址。这就引发出了两个问题：

- 既然使用物理地址读写物理内存，OS为什么不直接让应用进程使用物理地址？
- 应用进程使用虚拟地址，实际访问物理内存需要使用物理地址，谁负责这个地址翻译？

第一个问题将在本节介绍，通过了解关于OS内存管理的历史，能够回答该问题。第二个问题需要等到第三节介绍。

### 1.1 最早期的系统

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230417_091734.png)
最早期的计算机系统只允许一个进程执行，将 OS 和 进程 放在同一个物理内存中，进程直接使用物理地址读写内存，这会带来一个隐患：进程将会能够访问 OS 的数据和代码，造成系统的不安全。

### 1.2 多进程时代

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230417_092035.png)

后面的操作系统允许多道程序同时执行，支持中断机制，能够分时复用CPU资源、分时复用物理资源，但是他们还是处于同一个物理内存上，使用物理地址能够读写内存。这里存在两个问题：

- 进程可以读写操作系统的数据，不满足进程与内核隔离
- 进程可以读写其他进程的数据，不满足进程之间隔离

### 1.3 虚拟内存

**物理地址对应用是可知的，导致：** 

- 一个应用会因其他应用的加载而受到影响
- 一个应用可通过自身的内存地址，猜测出其他应用的加载位置

**是否可以让应用看不见物理地址？** 

- “看不见”，指应用对物理地址不可知 
- 一个进程不用关心其他进程占了什么地址，不受其他进程的影响 
- 看不见其他进程的信息，带来更强的隔离能力

为了解决物理地址带来的问题，CPU 和 OS 共同推进了虚拟内存的出现。

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230417_092556.png)

虚拟内存是对用户的一个抽象间接层，引入了间接层之后，物理内存由操作系统控制，OS能够控制进程可以看到什么、不能看到什么。之前的物理地址访问不能检查权限，由于间接层的存在，CPU 为虚拟内存提供了权限检查，每一次访问虚拟地址，如果没有通过检查将会报错。

> 虚拟内存的两个安全保障：OS 可以控制进程可见空间；CPU 可以检查进程访问权限

**虚拟内存抽象下，程序使用虚拟地址访问主存** 

- 虚拟地址会被硬件"自动地"翻译成物理地址 

**每个应用程序拥有独立的虚拟地址空间应用程序**

- 认为自己独占整个内存 
- 应用程序不再看到物理地址 
- 应用加载时不用再为地址增加一个偏移量

**这里可以回答上面的第一个问题：为什么不直接用物理地址？**

- 保证进程隔离，保证权限安全
- 进程地址空间连续且统一，方便共用物理地址空间，降低编程复杂度


## 2. 分页机制和分段机制

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230418_074848.png)

CPU 访存可以把物理内存看成一个巨大的数组，通过物理地址能够访问一个对应的字节，这个地址就是内存的物理地址。CPU 通过总线发送物理地址的读写请求，物理内存中的控制器负责响应请求，使 CPU 能够从物理内存中读取数据或者写入数据。

引入虚拟内存之后，OS 可以设置 CPU 的某些寄存器，表示开启了虚拟内存机制。应用进程可以使用虚拟地址进行数据读写，CPU 知道开启了虚拟内存机制后，就会将虚拟地址翻译成物理地址，用生成的物理地址发送给控制器。如若没有开启，则直接发送地址。

如何将虚拟地址翻译成物理地址呢？这个工作由 CPU 中的内存管理单元 MMU 负责，支持两种不同的机制，分段机制和分页机制。

### 2.1 分段机制

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230418_080908.png)

在 x86 平台上，MMU 支持分段机制，将段地址翻译成对应的线性地址。这里解释一下：

- 分段机制中，OS 将内存管理成一个个段的形式，如代码段、数据段等。用户、OS 使用一个段+段内偏移量来访问一个物理地址
- 段的信息被存储在段描述符中，注册在段描述符表，分为 GDT 和 LDT
- 用户可以通过段寄存器存储段选择子，来选择要使用哪个段，比如 SS：SP 中，SS 表示栈段的段选择子，SP 表示段内偏移
- 线性地址就是 **段基址+段内偏移** 组成的地址

**MMU 在分段机制下的地址翻译过程**：

- 虚拟地址由段号+段内地址组成
- 段描述符表基址存储在 GDTR 寄存器中
- MMU 首先根据段选择子（也就是段号+一些信息）去访问段描述符表
- 从段描述符表中能得到段的一些信息，譬如段长、段的访问权限等，这里会进行权限检查；翻译时会获得段基址
- 使用段基址+段内偏移拼接而成，获得对应的物理地址

分段机制下，不同虚拟内存空间被分为不同段，物理地址也以段为单位进行分配。段为分配单位容易出现外部碎片和内部碎片，是很难解决的问题。而且不同段的执行可能要频繁切换段选择子，是一个很大的开销。

80286 使用的就是分段机制支持虚拟内存，后面的 386 开始支持分页机制，不过会向前兼容 286 的分段机制。

### 2.2 分页机制

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230418_081640.png)

现在主流的 CPU 都用分页机制代替分段机制，应用进程的虚拟地址空间被划分成连续的、等长的虚拟页，虚拟页页长和物理页页长相等。任意虚拟页可以映射到任意的物理页。因为一个页很小，所以内部碎片不会浪费很多，而供分配器使用的外部碎片也会减小。

操作系统需要一个表存储虚拟页到物理页之间的映射关系，即页表。页表基地址需要存储在一个特定的寄存器，称为页表基地址寄存器，x86 中是 cr3，AArch64 中是 TTBR。

页表中不需要存储虚拟页号，存储对应的物理页号和一些权限信息位等。假设页表连续，通过下标访问就能得到对应的物理页号，和页内偏移拼接成物理地址。

具体的细节可以在地址翻译中查看。

### 2.3 段页式机制

x86 还支持段页式机制，即既使用了分段机制，又使用了分页机制。这是为了利用到分段机制中 CPU 提供的一些权限保护，而且利用分页机制还减少了内存碎片。段使用在虚拟地址空间中，不同段的范围可以重叠。

- 虚拟地址由段基址和段内偏移组成
- 访问地址时会先将虚拟地址转换成对应的线性地址，也就是 段基址+段内偏移
- 此时是线性的虚拟地址，如果是分段机制就已经是物理地址了！
- 将虚拟地址根据页表翻译成对应的物理地址

段页式机制看起来十分复杂，系统需要配置段表和页表。实际上，现代 OS 将段选择子采用平坦模式，即段数量很少，而段基址都是0，段长都是用户地址空间最大值，所以无论是进程执行、切换进程都不需要频繁切换段选择子，又减少了一点开销。


## 3. 地址翻译

这里详细讲解分页机制的地址翻译流程。

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230418_085941.png)
虚拟地址被分为虚拟页号和页内偏移，分页机制只需要将虚拟页号转换成物理页号就能完成地址翻译。每个进程的页表基址在物理内存中的地址不同，所以切换进程时需要切换页表，也就是设置页表基址寄存器，从而完成不同进程空间的转换。


### 3.1 多级页表


![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230418_090416.png)

假如使用单级页表，一个页表占用的空间很大，为了保证页表连续可以用下标访问，单级页表需要全部连续的存储在物理内存中，中间不能缺空，换入换出需要将整个页表都换入换出，而且分配页表时需要一次性将所有的页表项都分配出来。

这样无疑是一个巨大的空间浪费，很多页其实没有被使用到，因此使用了多级页表优化，优化的角度实际上有两点：

- 不用一次性分配所有页表项、允许有空洞、允许延迟分配
- 不用连续的存放在内存中

![IMG](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230418_091434.png)

多级页表就是将虚拟页号划分成多个部分，分为虚拟页表 1、2、3...，其中虚拟页号i对应该虚拟地址在第 i 级页表中的索引。任意一级页表中的某一个条目为空，该条目对应的下一级页表不存在。因此，多级页表允许整个页表结构出现空洞，而单级页表需要每一项都存在。由于大部分虚拟地址不会被使用到，可以极大的节约空间，即使都使用到，不连续的特质也比单级页表好。

0 级页表的物理地址存储在 TTBR 寄存器中，除了 0 级页表仅有一个之外，其他每级页表都有多个若干离散的页表页。每个页表页只有 512 个页表项，每项 8 个字节，4096/8，用于存储物理地址和权限。

物理内存被分为连续的、4KB 大小的物理页，一个虚拟页可以映射对应一个物理页。AArch64 分为4级页表，页表起始地址存储在页表基地址寄存器中，AArch64 在 EL1 提供了两个基地址寄存器，分别是 TTBR0_EL1 寄存器和 TTBR1_EL1。当虚拟地址 63~48 位全为0时，使用 TTBR0_EL1，反之使用 TTBR1_EL1，对比 x86 只使用一个 CR3 寄存器。64位虚拟地址被划分为如下几个部分：

- **64~48位**：必须全0或者全1(硬件要求)，通常OS选择全0时是应用进程，那么虚拟地址空间可以达到 2^48 字节。
- **47~39位**：这9位作为第 0 级页表的索引值
- **38~30位**：1级页表索引 
- **29~21位**：2级页表索引 
- **20~12位**：3级页表索引
- **11~0位**： 页内偏移

翻译的流程是：

- 根据页表基址寄存器找到页表，然后用 `47~39` 位作为页表项索引，读取第 0 级的页表中的页表项，该页表项存储第 1 级页表页的物理页号。
- 使用物理页号 <<12 作为索引的起始地址，然后用 `38~30` 位作为页表项索引，读取第 1 级的页表中的页表项，该页表项存储第 2 级页表页的物理页号。
- ...不断递归直到找到第 3 级页表
- 第 3 级页表中可以获得最终对应的物理页中的物理页号，使用 `物理页号<<12 + 页面偏移` 可以获得全部的物理地址

多级页表最大的优势就是不依赖内存页的连续性，因此能够在应用使用虚拟地址较少时降低页表占用的内存。64 位CPU，每个页表项是8字节，那么常用的是4级页表（`9*4+12`）；x86 现在推出 52 位物理地址和57位虚拟地址，操作系统使用 5 级页表（`5*9+12`）

### 3.2 页表使能

页表使能也就是 Enabling the Page Table。这里介绍一下如何在 AArch64 中开启页表机制。

基本上 CPU 在上电之后都是默认在物理寻址模式，想要进入虚拟内存模式，需要 OS 配置系统控制寄存器，开启页表机制。

- **AArch64**：需要修改 **SCTLR_EL1 （System Control Register, EL1）**，将第0位（M位）置1，即在 EL0 和 EL1 权限级使能页表。
- **x86_64**：需要修改 **CR0**，第31位（PG位）置1，使能页表

### 3.3 页表项和大页

实际上，多级页表中并非只有最后一级的页表项能够指向物理页，中间级别的页表项也能够直接指向物理页，而不是只能指向下一级页表页。但为了区分，中间级的页表项指向物理页时，指向的是大页，即比下一级页表项指向的物理页还要大。（0 级页表大页大小 > 1级页表大页大小 > 2 级页表大页大小 > 普通页的 4KB）

此外，页表项除了存储物理页号（下一级的页表页或者指向的物理页）之外，还会存储一些属性位，允许操作系统设置诸如读写执行等权限，当访问权限和页表权限不一致时，MMU 在地址翻译的过程中会发生 **访问异常**。

我们将页表项分为三种类型：

- **页描述符**：第三级页表的页表项作为页描述符，存储的物理页号是一个页
- **表描述符**：第0、1、2级页表的页表项，当第一位为 1 时，是一个表描述符，存储的物理页号是一个页表页
- **块描述符**：第0、1、2级页表的页表项，当第一位为 0 时，是一个块描述符，存储的物理页号是一个大页的起始地址

每一级页表的大页，对应的大小都是固定的，这样子 CPU 才能完成翻译。当使用大页映射时，虚拟大页被映射到相同大小的物理大页，物理大页地址连续而不是离散。这样的优点是大大减少了页表，缺点是翻译粒度变粗。

第二点，大页映射可以与 4KB 页映射在同一级页表中共存。第三点，大页和4kb页一样，仅仅是逻辑上的概念，和物理内存没有直接关系。

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230419_063029.png)

当 bit1 为0时，表示块描述符，否则是页描述符。

 
![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230419_065100.png)

这个是表描述符的前几位，用来指示下一级翻译表访问的权限。表描述符的结构和页描述符不太相同。

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230419_063309.png)

通过系统控制器可以设置页的粒度，可以设置为 4KB、16KB、64KB。页描述符和块描述符的属性位基本相同。这里介绍一下描述符中的常用的各个属性位，各个属性位分别存储在 `Upper attributes` 和 `Lower attributes` 当中：

| 字段 | 位 | 描述|
| --- | --- | ---|
| UXN | bit[54] | 置为 `1` 表示非特权态无法执行（Unprivileged eXecute-Never）; 比如将栈段设置为不可执行 |
| PXN | bit[53] | 置为 `1` 表示特权态无法执行（Privileged eXecute-Never）; 比如用来防止内核态错误执行用户态代码 |
| DBM | bit[51] | 置为 1 表示脏页 |
| nG | bit[11] | 置为 `1` 表示该描述符在 TLB 中的缓存只对当前 ASID 有效 |
| AF | bit[10] | 置为 `1` 表示该页/块在上一次 AF 置 `0` 后被访问过; 如果 AF 为 0, 会触发访问标志位异常, 可以用来给软件追踪内存访问情况, 在后面的页面回收中会涉及到 |
| SH | bits[9:8] | 表示可共享属性[^mem-attr]; 用于核间、核与设备间的共享 |
| AP | bits[7:6] | 表示读写等数据访问权限[^mem-access] |
| AttrIndx | bits[4:2] | 表示内存属性索引，间接指向 `mair_el1` 寄存器中配置的属性[^mair_el1]，用于控制将物理页映射为正常内存（normal memory）或设备内存（device memory），以及控制 cache 策略等 |
| Page | bits[1] | 表示描述符类型; 在页描述符中表示是一个页, 在 L0,1,2 页表中若为1, 表示是一个表描述符, 否则表示一个块描述符|
| Valid | bits[0] | 表示该描述符是否有效; 在按需映射换页时如果检查到不存在就会触发缺页异常 |

CPU 允许 OS 为异常、系统调用、中断编写相应的异常处理函数。所以这里的缺页异常可以设置异常处理函数，在后面的页面按需分配过程中， MMU 查询页表发生缺页时，将会根据缺页异常执行我们编写好的程序。

ARMV8.0 中，AF 只能由软件进行设置，也就是需要操作系统进行设置。而在 ARMV8.1 当中，AF 可以由 MMU 进行设置，地址翻译时，MMU 会自动设置页表项的 AF 为 1，不触发异常；页表项还引入了 DMB 位，当地址翻译发生且进行的是写指令，MMU 将会自动将页表项中的 DMB 设为 1。

>**缺页异常**：
>
>在 x86-64 体系架构下，缺页异常的异常号是 14，发生错误的页面地址会是 CR2 寄存器；
>在 AArch64 体系结构下，缺页异常没有专门的异常号，二世和其他用户态同步异常共用一个异常号，即 8 号同步异常。操作系统根据 ESR（错误症状寄存器）判断发生的异常是不是缺页异常，如果是的话，从 FAR_EL1 寄存器获取发生缺页的虚拟地址。同样，OS 也是从 ESR 寄存器获取是不是标志位异常。


### 3.4 TLB

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230419_071716.png)

多级页表能够压缩页表空间，但是也增加了访存次数，引起地址翻译时间的增加。例如，一次翻译操作需要访问四级页表，那么需要访问4级页表项，比物理地址直接访问多带来了四个额外的访存操作。

**那么，如何减少地址翻译的开销呢？**

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230419_072115.png)

MMU 引进了 TLB 来加速地址翻译，TLB 存储了虚拟页号到物理页号的映射关系（不仅仅是物理页号，为了权限检查还包括了属性位，也就是说是存储了一个页表项），MMU 获得一个虚拟地址，会根据虚拟页号先去查找 TLB，如果命中的话直接就获得了物理页号。如果不命中的话会去逐层翻译获得这个物理页号，然后填写到 TLB 当中。

TLB 带来了什么好处？假如有 TLB，地址翻译只需要一次寄存器访问，与访存相比可以忽略不记。假如没有 TLB，地址翻译就需要四次访存。

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230419_072717.png)

根据局部性原理，TLB 不命中的次数非常少。为了更加利用局部性，CPU 采用 L1、L2、L3 三层的 cache 分层，其中 L1、L2 位于 CPU 内部。TLB 的体积很小，所以每个 CPU 核心大约只有 1000 项缓存页。当 TLB 不命中时，硬件可以通过页表获得对应的页表项，将翻译结果存入 TLB 当中。当 TLB 满时，电路根据对应的置换策略替换某一项。之后再次访问这个虚拟地址时，将会直接命中。

>在一些体系结构（如MIPS）中，TLB由软件进行管理，即“software TLB”，TLB未命中时触发异常，然后由 OS 从页表进行地址翻译获取物理地址，使用特殊的指令更新 TLB，异常结束后重新执行指令。**软件的优势在于灵活性，不会写死替换策略，比如可以 ai for xx？但是性能不一定可观**

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230419_073207.png)

>关于同一进程在内核部分、用户部分执行时，TLB 是否要更新可以看上面。对于 AARCH64，内核部分的虚拟地址前16位都是 1，而用户部分的虚拟地址前16位都是 0，TLB 不会出错。

TLB 引入带来了一个新的问题，如何保证页表和 TLB 内容的一致性？比如说：

- 页表项的物理页号被修改，TLB 要怎么办？
- 不同进程同一虚拟地址指向不同的物理地址，切换进程时 TLB 要怎么更新？

对于第一个问题，只要每次读写都是优先从 TLB 开始读写就可以了。
对于第二个问题，首先每个 CPU 核心都是私有的 TLB，所以并行时不会出错。而并发切换进程时，OS 需要强制的刷新 TLB，但是我们需要保证切换页表时全部将 TLB 的内容全部清空吗？

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230419_074011.png)

全部切换的效率十分低下。每当进程被切换到时，此时 TLB 为空，命中的效率十分低下。所以有没有一种办法可以在切换进程时不刷新 TLB，延迟刷新呢？

一种方法就是给 TLB 缓存项打上标签，说明他属于哪个进程，当访问时如果虚拟地址相同，但是当前进程和标签上的进程id不相同，才刷新这个 TLB 缓存表项。以 AARCH64 为例，它提供了地址空间标识符（Address Space ID，ASID）；具体地说，操作系统可以为不同的应用进程分配不同的 ASID 作为应用进程虚拟地址的标签，将这个标签写入应用进程页表基地址寄存器的空闲位（比如 TTBR0_EL1 的高 16 位）。

TLB 的缓存表项也会彪悍这个标签，从而可以把不同进程的缓存区分开了。这样子只有在缓存项的 ASID 和 TTBR0_EL1 保存的 ASID 一致时才会使用 TLB。切换页表时，操作系统不需要清空 TLB 缓存项。

在使用 ASID 之后，切换页表项不需要刷新 TLB，而修改也表映射需要刷新 TLB。那么就带来一个问题，在多核场景下，需要刷新其他核的 TLB 吗？

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230419_075502.png)
需要刷新其他核的 TLB，因为缓存项的物理地址被修改了！！AARCH64 提供了多个粒度的 TLB 刷新指令，OS 可以根据自己的 workload 进行选择。

- 清空指定虚拟地址
- 清空指定 ASID
- 清空全部

> 属性位的 NG 位，ng 为0表示 TLB 缓存项对所有进程有效；ng 为 1表示只对特定进程有效；划分 ng 位可以进一步划分内核地址空间和虚拟地址空间，访问内核空间会带来更好的性能

### 3.5 抽象与虚拟

总结一下，虚拟内存就是 OS 提供给用户的接口。利用了地址翻译的透明性，用户只知道使用不需要实现方法。

同时，地址翻译也保证了策略与机制分离，譬如 CPU 需要翻译地址是一个策略，而实际的 TLB、TLB 维护、访存更新是一个机制。


## 4. 操作系统的职责

前面说了 CPU 负责地址翻译，但是 CPU 不能主动填写进程页表。所以管理页面映射和属性位的工作就交给了 OS 来完成。

### 4.1 内核页表

CPU 在上电之后默认使用物理地址，等开启分页机制后，CPU 会默认此时所有的地址都是虚拟地址，从而进行翻译执行。所以 OS 和应用程序执行过程的地址都是虚拟地址，OS 也需要为自己配置页表。

OS 为自己配置的页表有两个特点：

- 操作系统使用的虚拟地址，前16位全为1
- 操作系统会一次性将全部物理地址映射到虚拟地址空间中，即虚拟地址 = 物理地址+固定偏移。这种映射方法叫直接映射。

操作系统所使用的虚拟地址空间称为内核地址空间。当 OS 需要访问一个物理地址时，直接用 物理地址+固定偏移 就能访问。

这么一来，64位的虚拟地址空间可以划分为：

- `0~2^47-1`：用户地址空间
- `2^47~2^64-2^48`：无效虚拟地址
- `2^48~2^64-1`：内核地址空间

由于 AARCH64 使用两个页表寄存器，`TTBR1_EL1` 存储固定偏移的内核页表，与 x86相比，这个寄存器的值一经初始化就可以不用再修改了。而每个进程都有一个独立的页表，存储在 `TTBR0_EL1` 寄存器当中，每次切换进程时，寄存器都要修改成其他进程的页表物理地址。

### 4.2 进程页表

不同进程使用相同的虚拟地址可以映射到不同的物理地址，而为了防止丢失进程页表，页表可以作为一个成员变量存储在进程 PCB 当中。

具体实现中，OS 为进程创建页表只需要分为 0 级页表，无需创建完整的页表。通过按需分配，就能够体现页表节约内存的优势。

### 4.3 何时填写页表？

追述上一个问题，何时填写进程页表？进程虚拟地址空间包含若干个虚拟内存区域，如代码段、数据段、用户堆栈、其他代码库。在应用进程的生命周期中，虚拟内存空间变化主要包括：

- **进程创建时**：OS 将应用二进制文件和动态代码库加载到物理内存，并在应用进程的页表中完成映射。
- **进程执行时**：应用进程要求主动改变虚拟地址空间，可以分为三种情况：进程的堆栈空间减小或增加；进程加载或者卸载代码库；进程通过调用 mmap 接口增加新的虚拟内存空间，munmap 删除已有的虚拟内存区域。
- **进程退出时**：操作系统删除应用进程的页表，即删除整个进程虚拟地址空间。

----

每个虚拟内存区域由连续的虚拟页组成，操作系统何时在进程页表中为虚拟内存区域添加到物理内存的映射呢？一种映射策略是 **立即映射**。在创建时、执行时，一有请求就立即申请物理页并建立虚拟页到物理页之间的映射。

虽然简单但是会带来不少问题：

- 比如游戏、应用的启动时延
- 比如关于内存的浪费，很多代码段数据段可能不会被用到

----
那么操作系统如何解决立即映射策略带来的问题呢？一种方法是，OS 根据进程运行过程中的实际需要进行物理页分配和页表填写，避免分配的物理页实际不被用到的情况。为此，OS 设计了**延迟映射**，将虚拟内存的分配与物理内存的分配解耦开来。

与立即映射不同，延迟分配先记录为应用进程分配的虚拟内存区域，但不分配相应的物理内存，也不会在页表中填写映射；应用进程实际访问某个虚拟页时，由于页表没有映射，CPU 会触发缺页异常，进入异常处理程序。

可以提前规定页表项的某一位**标志为延迟分配**（比如 x86 有3个软件可利用位，可以用来标志为延迟分配），如果 OS 查看这位存在，就知道他是延迟分配，这时候按需分配物理页和映射，然后重新执行指令。

上面是页的角度。还有另一种做法是在进程结构体中，记录各虚拟内存区域，作为一个成员变量存储，每个虚拟内存区域由 vmregion 结构体表示，包括区域的起始地址、结束地址、访问权限。

在创建进程或者运行过程中，可以在上面的虚拟内存结构体链表中增加一项。比如初始化由堆、栈、代码段，通过 mmap 调用时可以新增加一个 vmregion 段。添加虚拟内存区域并不会为其分配物理页、添加页表映射，在首次访问虚拟页时会触发缺页异常，根据缺页异常来判定虚拟地址是否属于某一个虚拟内存区域，并且检查读写权限是否匹配，然后分配物理页添加映射（按需分配可以只分配一个页，也可以全部分配）。

那么在游戏、应用启动的时候，推迟映射可以减小时延，提供物理内存资源的利用率。相比于立即映射，延迟映射（按需分配）优点在于不浪费内存，缺点是多个缺页异常会对一些情况下的应用性能带来影响（空间局部性）。因此，OS 做了一些妥协。比如应用进程调用 mmap 的参数可以设置参数，立即分配还是延迟分配。

**平衡**：

- 访存具有时空局部性
- 缺页异常处理函数采用预取机制，解决内存又能减少缺页异常次数。

>**VMA**：Linux 中使用 vm_area_struct 包括起始虚拟地址，结束虚拟地址，访问权限等信息。Linux 使用平衡树将不同虚拟内存区域组织起来。

>**段错误**：段错误不等于缺页异常，段错误是OS规定的，如果缺页的地址有问题、在异常处理程序中会报错；缺页异常是CPU规定的。

OS 虽然允许延迟分配，但还是要注意，只有进程告知OS要分配这段区域，OS才知道这段区域是安全的，不会发出段错误。

### 4.4 改变虚拟内存的接口

>**api 和 abi**：os 向用户提供系统调用，mmap、munmap、brk、sbrk，这些称为 abi 接口。而 mmap、munmap、malloc、free 接口是 c 库向应用进程提供的，接口属于 api 接口，这些接口是 abi 接口的包装。

用户进程可以通过几个函数来改变虚拟内存：

- **malloc、free**：控制堆区的分配和释放，使用 brk 实现，用来管理堆区大小。
- **mmap、munmap**：mmap 新增一段内存区域，munmap 删除一段内存区域。在 munmap 的实现中，不仅时删除内存区域 vm_struct，还删除映射，刷新 TLB。
- **栈区**：创建进程时就新建一定大小的栈，加入虚拟地址区域。然后按需分配新的物理页


## 5. 虚拟内存拓展

### 5.1 共享内存

主要是同一个物理页在不同的应用程序间共享，也就是用户地址空间中，两个进程的不同虚拟页映射到同一物理页，互相可见对方的修改。

### 5.2 **写时拷贝**

写时拷贝复用了共享内存的思想。两个进程假如有父子关系或者有同一代码库，相同的内存数据在物理内存只存一份，设置页表项，以只读的方式分享给两个进程。

当其中一个进程需要修改数据时，CPU 会触发异常进入 OS 的处理函数，当发现异常是写只读内存且该页写时拷贝时，就会将异常对应的虚拟页重新分配物理页和建立映射，然后重新执行用户指令。

写时拷贝的好处：

- 节约物理内存资源，比如写时拷贝的方式映射相同动态链接库的可写部分
- 写时拷贝让父子程序只读的共享内存数据，减小或延迟内存拷贝开销

### 5.3 大页

提供 TLB 命中率可以降低地址翻译的性能开销。但是翻译每个内存页都需要占用一个 TLB 缓存项，因此 CPU 中有限的 TLB 缓存变得弥足珍贵。在内存页大小为 4kb时，访问 2mb 内存需要 512 个tlb缓存页。

大页可以减少 tlb 缓存项不足的情况，大页的大小可以是 2mb、1gb、512gb。相较于 4kb 大小的页面，大页可以减少 tlb 占用量。

> TLB 存储页表项，根据属性位知道是大页

OS 可以根据硬件的大页支持，在添加页表项时自动进行大页映射。Linux 还提供了透明大页，自动将 4KB 内存页合并成 2mb 内存页。使用大页好处：

- 减少 TLB 缓存项，提供 TLB 命中率
- 减少页表级数和增加查询效率
- **缺点**：OS 管理内存复杂，不再是以页为固定单位，有不同的页大小，而且过度的大页会带来资源浪费

### 5.4 cache lockdown

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230419_070534.png)
`Cache lockdown` 就是缓存锁，具体看 ppt

## 6. FAQ

**课后习题**

**1.页表基址寄存器存储的是虚拟地址还是物理地址？**
物理地址，因为页表就是为了完成地址翻译，所以使用虚拟地址无法翻译成物理地址会出错

**2.为什么单级页表每一项都需要存在，物理内存连续？**
否则无法连续索引

**3.页面大小为8kb、依然是4级页表，虚拟地址的有效位为53位或48位，怎么划分64位虚拟地址呢？**

8kb 等价于一个页有 512 个页表项，那么一级页表占据 9 位虚拟地址。所以需要

- 48 = 9 + 9 + 9 + 9 + 12
- 53 = 9 + 9 + 9 + 9 + 17

**4. 四级页表中，虚拟地址各级索引是什么？**

- **0x8080604000**：

**5. 按照四级页表，(1)如果页表总共占用16kb，那么至多翻译多大的虚拟地址范围，(2)如果页表中填写虚拟地址0~16mb的映射，页表需要占用多少空间？**

- (1)一个页表占用 4kb，那么只有一个三级页表页，至多翻译 2mb
- (2)一共有四级页表，一个页表页存储2mb空间，则三级页表需要有8个页表页，总共有 1+1+1+8 = 11，一共 44kb

**6.为什么上一级页表项能够指向的物理页大小总是下一级页表项能够执行的物理页大小的512倍？**

页表中可以有512个页表项

**7.CPU翻译如果发现最后一级页表页表项的有效位0，且当前写访问而页表项中AP设置的是只读，那么触发缺页异常还是访问权限异常？**

首先检查缺页异常，缺页就不会检查页表项的内容

**8. 为什么TLB的空间很小、CPU管理方式很简单，却可以提高命中率？**

局部性

**9. 在 aarch64 上**

- 若操作系统页表基地址存在 TTBR1_EL1，进程页表基地址存在 TTBR0_EL1，发生系统调用要不要 TLB 刷新？

不需要

- OS 为两个进程页表设置不同 asid，进程切换时要不要刷新 tlb？

不需要

- 需要 tlb 刷新的两个例子

进程修改了页表项内容，需要通知其他cpu上的tlb

**10.OS自己访存是虚拟地址还是物理地址？**

虚拟地址

**11. add_mapping 函数在逐级查找页表项过程中可能发生页表页不存在，delete_mapping 函数会遇到该问题吗？遇到了怎么解决？**

delete_mapping 可能会遇到，比如进程回收时，某一级页表还没有映射。直接返回就行

**12. 进程虚拟地址空间由若干段虚拟内存区域组成，是否分段比分页更合适？**

分段有两个不足：

- 每个虚拟段的内存要全部分配，并且要 all or nothing
- 虚拟内存段的大小变化较为困难，要保证物理内存段的增大；很容易造成浪费，比如减小虚拟内存段后释放的空间太小而无法加以利用

**13. 进程不同虚拟内存区域组织在一起，用树查找的优势？**

与链表相比，on 变成 ologn

**14. OS 使用 4kb 作为最小页，L2和L1页表项对应的大爷页面大小分别是2mb和1gb，那么OS选择16kb或者64kb，对应大页的页面大小是多少呢？（注意，ARMV8.0，使用 16kb or 64kb，只有 L2 页表项支持大页**

一个页表页可以存储：16kb/8b = 2024 个页表项。那么对应大页的页面大小 = 2024*16kb = 32mb

同理，64kb/8b = 9096，大页 = 9096 * 64kb = 512mb

**15. 操作系统页表是否适合大页映射？**

操作系统页表使用的直接映射，所以适合大页映射

----

**思考题**

**1.单级页表需要占据连续的物理内存吗？为什么？**

需要，否则无法连续索引

**2.ng位为1时表示tlb缓存项支队指定的进程有效；ng位为0时对所有应用进程都有效；为什么需要 ng 位，通常应该设置为 0 还是1？**

- 内核部分：设置为 0，提供cache命中率
- 用户部分：设置为1

**3.单级页表 64位虚拟地址空间，页表应该多大**

2^48 / 2^12 = 2^36

**4. 当下主流的体系结构使用 TLB 分级，采用数据和指令分离的设计。请从TLB命中速度和 TLB 命中率的角度思考为什么需要分级和分离？**

分级：利用好空间局部性，越小的 TLB 级别查询越快
分离：也是局部性，在 OS 里面，代码段和数据段虚拟地址通常相距甚远

**5. 非易失性内存 NVM，速度接近内存但是容量媲美硬盘，访存方式和内存相同，思考 NVM 如何革新存储层次**

内存更大，那么可能不需要交换区和进程执行时换页了

**6. 硬件提供大页机制，且 AArch64 体系结构支持不同大小的最小页大小，什么时候适合用大页或者更大的最小页面？**

- 大页：比如数据库的缓冲池，或者映射内核页表
- 更大的最小页：用户可能需要更大的粒度，减少页表级数

**7. 假设物理内存足够大，虚拟内存是否有存在的必要？不使用虚拟内存抽象，只靠物理地址寻址，会带来什么改变？**

有。因为虚拟内存带来更好的编程便利，比如用户地址空间形式统一和进程隔离性好！变化是很不方便、不安全。

**8. 不靠 MMU，是否有替换虚拟内存的方法**

- 基于高级语言实现多个同一个地址空间内运行实例的隔离
- 基于编译器插桩实现多个运行实例的隔离


>换页现在还需要吗？物理内存越来越大，内存已经够用了？服务器内从通常有上百GB；非易失性内存的出现
