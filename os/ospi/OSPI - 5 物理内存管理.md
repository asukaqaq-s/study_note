
在内存管理方面，OS 除了担负管理页表映射的职责，还担负着管理物理内存的职责。各个应用进程在运行过程中需要使用物理资源，操作系统需要为他们分配物理资源。

- 一方面，OS 具备以物理页为粒度进行物理内存分配，从而在应用进程的页表中填写虚拟页到物理页映射
- 另一方面，要具备分配小内存区域的能力，否则会造成内存浪费
- 物理内存资源是有限的，所以需要换页机制，把物理内存中的数据暂时换出到磁盘上以释放空闲的物理内存

在进程物理分配的过程中，可以结合实际的硬件特征设计提升应用进程性能的分配策略。

- OS 如何管理和分配物理内存页和小内存块
- OS 如何设计与实现换页机制
- OS 中性能导向的物理内存分配策略

## 1. 管理物理内存资源


### 1.1 内存控制器

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230420_080625.png)

我们知道 DRAM 的组成是很复杂的，每个地址单元都是一个小方框。内存控制器隐藏了具体的硬件细节，可以看成是硬件给软件的一个接口

### 1.2 物理内存管理评价

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230420_081547.png)
操作系统物理内存分配设计有两个重要的评价维度：

- 物理内存分配器为了追求更高的资源利用率，尽可能减少资源浪费
- 物理内存分配器要追求优秀的性能，尽可能降低分配延迟和节约 CPU 资源

内存碎片分为外部碎片和内部碎片。外部碎片是动态的，比如一个请求i将所有空闲但是无法使用的块称为外部碎片，而有些块对于其他请求能满足，就不是这个请求的外部碎片。

物理内存分配器需要追求优秀的性能，通过精致的分配算法能够减少空间浪费但是可能会带来高昂的性能开销。

所以一个好的分配器需要 trade off 这两点

### 1.3 伙伴系统

简单的分配器其实在 CSAPP 里面就见过了，主要的形式是 位图(bitmap) 和 链表：

- **位图（bitmap）**：每个页以一个 bit 为单位表示是否分配。分配n个连续的页时，需要查看n个连续的0，然后全部设置为1
- **链表（link list）**：链表的每个成员都是一块连续的物理页，当分配时不是完全分配，而是会带来分裂，释放时进行合并。有隐式链表和显示链表

书中介绍了一个新的分配算法，伙伴系统。

伙伴系统基本思想是将物理内存划分成连续的块，以块为作为基本单位进行分配。不同块的大小可以不同，每个块都由一个或多个连续的物理页组成，每个块中物理页的数量必须是 2 的 n 次幂。

>2 的 n 次幂即表示二进制下只有一位为1，这么说来假如 2 mb 和 4kb 两个块连续，也不会合并

这里介绍分为 **初始化、分配、释放**

#### 1.3.1 初始化

初始化时，分配器将会将物理内存划分为多个预设最大值的块。其中预设最大值将决定能够分配的连续物理内存区域的最大值，由 OS 设置。

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230420_090936.png)

伙伴系统中存在一个最大的大小为64 的链表数组（即数组大小为64，不同系统情况可能不同），每个下标存储空闲链表的初始地址。初始化时是将预设最大值的块全部插入对应的链表中。

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230420_091212.png)

为何称为伙伴系统，就是两个大小相同且连续的物理块互为伙伴。举个例子，比如一个物理块大小为 `2^k` 次方，他们都位于 `链表数组[k]` 指向的链表当中。物理地址中，两个伙伴的物理地址除了二进制下第 k 位不一样之外，其他的完全一样，通过 `物理地址 ^ (1<<k)` 就能找到对应的伙伴。

### 1.3.2 分配

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230420_091935.png)

当收到一个请求后，首先是算出需要分配多大的物理页，比如这里分配 15KB 的内存

- 此时空闲链表中没有 16K（2^0表示4kb，2^2表示16kb） 的内存，那么分配器或顺着数组向下寻找，第一个寻找到的就是 32KB 的物理块，假如这里没有寻找到，可能会找到 64KB 的物理块。
- 将 32KB 物理块划分成两个 16KB 的物理块，由于 8 < 15 < 16，那么就不会继续划分，而是使用这个物理块作为服务，另一个伙伴加入空闲链表当中

#### 1.3.3 释放

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230420_092606.png)
释放时，分配器首先根据二进制第k位，找到释放块的伙伴块。

- 如果伙伴位于非空闲状态，则将被释放的块直接插入对应大小的空闲链表中完成释放。
- 如果伙伴位于空闲状态，则将被释放的块和伙伴块合并，然后再插入 k+1 这一个空闲链表中

这个分配和合并的过程可以进行级联（即递归，不段合并或者不断分裂）

### 1.4 SLUB 分配器

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230420_093130.png)
伙伴系统中分配的最小物理块单位都是 `4KB`，实际 OS 在运行的过程中是需要使用到一些小的内存对象，比如结构体，又不想要他们存在于全局区和栈区，这些内存对象大概只有几十、几百KB，如果分配给他们一个页将会带来严重的内部碎片。

SLAB 分配器就是为了分配小内存的单位，但是SLAB由于过于复杂，比如维护太多队列，因此后面采用了更加简化的 SLUB，继承了 SLAB 分配器的接口。SLUB 分配器是为了满足内存资源稀缺的场景，比如嵌入式设备，但是对于碎片问题的处理比不上其他两个，在 LINUX 2.6.23 之后，SLUB 分配器成为 Linux 内核默认的分配器。

#### 1.4.1 设计

**SLUB 设计的思路**：

• **观察**：操作系统频繁分配的对象大小相对比较固定

**基本思想**：
- 从伙伴系统获得大块内存
- 进一步细分成固定大小的小块内存进行管理
- 块大小通常是 2^n 个字节（一般来说，3 ⩽ n < 12）可以额外增加特殊大小如198字节从而减小内部碎片

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/clipboard_20230421_032533.png)

slab 向伙伴系统申请到多个足够大的物理块（每个物理块之间连续），然后再对这些物理块进行维护，将获得的物理内存块作为一个 slab。slab 会被划分成**等长**的小块内存，并且将 slab 内部，**空闲的小块内存组织成空闲链表。**

#### 1.4.2 数据结构

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/clipboard_20230421_033752.png)

一个 slab 内的每个物理内存块都是等长的，然后物理内存块之间维护成一个空闲链表。这里分为三个指针来组织 slub：

- **current**：指向一个 slab，所有的分配请求都从这个 slab 中分配，待 slab 满了之后再换成下一个 slab
- **partial**：指向一个未满的 slab 链表
- **full**：指向一个全满的 slab 链表

#### 1.4.3 分配

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/clipboard_20230421_034255.png)

slub 分配器收到一个分配请求：

- 首先定位到一个能满足请求大小、且最接近这个大小的内存资源池
- 从 current 指针指向的 slab 中取出一个空闲的块返回
- 如果 slab 已经满了，将这个 slab 插入 full 链表，然后从 partial 链表中取出一个 slab 让 current 指针指向
- 如果 partial 链表为空，SLUB 分配器会向伙伴系统申请分配新的物理内存作为新的 slab

这样的分配设计一方面有效避免了外部碎片，另一方面分配速度很快，直接从 current 指针指向的 slab 中取出第一个空闲块即可。通过合理设置不同大小的内存资源池，能够减小内部碎片导致的开销。

#### 1.4.4 释放

释放时：

- 找到对应的内存资源池
- 找到对应的 slab，可能在三种指针中的一个
- 可能会发生 full 移动到 partial
- 如果 partial 全 free 就还给伙伴系统

长期下来，就可能在 partial 当中有许多的未满的 slab。

>Linux 操作系统内核中分配内存的接口称为 kmalloc。实现主要采用伙伴系统和 slab 分配器的设计。Chcore 也实现了这个接口，如果请求小于 4kb，就调用 slab 分配器，否则调用伙伴系统

>用户态下的 malloc 也是分配内存并创建变量，malloc 有多种实现方式，比如可以采用 SLAB 分配器的思路，或者空闲链表的思路。malloc 在用户态中，可以用 sbrk 修改堆区以获得一块大的 “slab”（Linux 会在用户不感知的条件下，分配物理页并建立映射），然后对每个 slab 进行划分。

#### 1.5 空闲链表

除了上面的伙伴系统和 SLAB 分配器，还有其他基于不同空闲链表的内存分配方法，不仅可以用在内核态，也可以用于用户态的 malloc 等。

- **隐式空闲链表**：链表中混杂着空闲块、非空闲块
- **显示空闲链表**：只维护空闲块
- **分离空闲链表**：维护多个不同的显示空闲链表

## 2. 获得更多的物理内存


### 2.1 换页

![IMG](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230419_092230.png)

换页机制可以把物理内存放不下的数据存放到磁盘上，等到需要时才换入，这样子就能提供超过物理内存实际的内存空间。换页机制能够给应用提供一个抽象，就是实际可以使用的内存资源 = 物理内存 + 磁盘空间的和。

执行换页时：

- OS 的缓冲池置换了一个应用进程 A 的虚拟页 V，对应物理页是 P。他会先将 P 的内容写到磁盘的交换区上，删除 V 映射，然后把 P 分配给其他进程，称为**换出**。
- OS 访问 V 时，发生缺页异常根据页表项的信息知道存储在哪一个磁盘扇区中，然后将其换入物理内存页 P2 当中，并建立 P2 和 V 的映射，称为**换入**。

换入之后，进程回到异常的指令处继续执行。

>**是否需要用完所有的物理资源才换页？** 实际上这样子做，每次到满才发生换页，会导致分配时延高的问题。OS 可以设立阈值，在空闲物理页低于阈值的时间内，OS 便选择时机进行换页，等到空闲页数量超过阈值就开始换出部分页。

LINUX 设置了三个阈值：

- 高水位线
- 低水位线
- 最小水位线

低于水位线就立即进行批量换出页面

>换页机制的缺点

- 缺页异常的分配时延；可以用预取优化，预取是双刃剑

>如何知道缺页时是按需页面导致还是换页导致

- MMU 根据页表项第 0 位判断映射是否存在
- OS 根据其他位标记区别按需分配和换页

### 2.2 页面置换策略

>Belady 异常：更多可用物理页面会导致更多换页，在 FIFO 或者 Second 中发送

换页机制：

- **OPT/MIN**：最优置换算法，需要知道未来的页面请求顺序
- **FIFO**：先入先出
- **Second Chance**：根据访问标志位+FIFO，每次检查队头，如果队头标志位1，则变为0放入队尾
- **LRU**：维护访问时间（可能是时间戳也可以是队列实现），优先选择最久未被访问
- **时钟算法**：循环队列扫描，每次从 index 指向的页号开始扫描，有一个访问标志位
- **随机替换**


### 2.3 工作集模型

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230419_092551.png)
抖动：大部分 CPU 时间用于处理异常和等待缓慢的磁盘操作。可能原因是：内存少、或者置换算法差。


![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/f3/clipboard_20230419_092711.png)

工作集模型可以防止颠簸。一个进程在时间t的工作集W(t, x) (Peter Denning)

- 其在时间段（t - x, t)内使用的内存页集合
- 也被视为其在未来（下一个x时间内）会访问的页集合
- 如果希望进程能够顺利进展，则需要将该集合保持在内存中

早期工作集模型是 all or nothing。进程工作集要么全在内存中，要么全部换出，避免抖动，影响系统整体性能。

现代工作及模型指导 OS 的换页策略，优先将非工作集的页换出

维护追踪工作集：

- 上次使用时间：每次访问就赋予当前系统时间
- 访问位：访问过设置为1

### 2.4 内存去重

通过定期扫描内存中有相同内容的物理页（除全0），找到映射这些页的虚拟页，然后只保留一个物理页，全部映射给他，设置为写时拷贝。操作系统发起，对用户态透明

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/clipboard_20230421_045326.png)
**攻击**：在内存中不断穷举构造数据，等待去重，通过访问时延是否变长知道是否有去重，然后可以窃取到数据

- 比如一个进程想要知道其他进程在内存中保存的变量 A
- 构造一个除了 A 其他都一样的内存页
- 不断枚举 A 的值
- 发生去重就猜对了

防御方法：只对同一用户的进程内存发生去重


### 2.5 内存压缩

内存资源不足时，选择一些不太常用的物理页，压缩数据但不写入磁盘，释放更多内存页，当进程访问这些页时，OS 将其解压，所有操作都在内存中完成

![img](https://image-1309461627.cos.ap-nanjing.myqcloud.com/image/markdown/os/clipboard_20230421_045851.png)
zswap 在换页过程中作为缓冲区，然后将准备换出的内存数据进行压缩，压缩后的内容写入到内存中的 zswap 区域。这样子可以进程更有效地磁盘批量 IO，甚至避免 IO，即使写入写出数据时，数据量因为压缩也会变得很小

### 2.6 Linux 内存管理API

- **mmap**：文件操作，与 read/write 相比避免特权级切换
- **madvise**：用户态的语义信息告诉内核，便于优化。

## 3. 性能导向的内存分配机制

### 3.1 物理内存分配与 CPU 缓存

分配的物理页尽可能均匀地占用 CPU 缓存组，这样子能够带来更大的应用性能提升，提出一个缓存着色的内存染色机制：

- 将能够被存放到缓存不同位置的物理页染上不同颜色
- 为连续虚拟页分配时，优先分配不同的颜色物理页
- 这样子不同颜色的物理页可以让被访问的数据处于缓存中，不引起冲突

### 3.2 多核与内存分配

为防止锁代价，为每个 CPU 核心都初始化一个 SLAB 分配器，根据 CPU 核心调用对应的 SLAB 分配器

### 3.3 CPU 缓存的硬件划分

对 L3 缓存进行不同 CPU 的分区划分，这样子能够带来更大的性能提升

### 3.4 NUMA 架构

随着多处理器系统的出现和单处理器中核心增加，单一的内存控制器称为性能瓶颈。多处理器或者多核系统将为每个核心分配一个内存分配器。每个节点可以：

- 通过本地内存控制器访问本地内存
- 通过远端内存控制器访问远端内存

远端内存的访问时延高，称为**非一致内存访问（NUMA）**

## 4. FAQ

**例题**：

**1. 为何分配连续的物理页**

只分配单个物理页，无法满足分配大页的需求。而且设备和CPU进行数据传输也需要分配连续的物理页作为 DMA。

**2. 伙伴系统最理想和最差的时间复杂度**

O(1) O(BUDDY_MAX_ORDER)

**3. 是否需要分配 full 指针指向全满的 slab 链表？**

可以分配 full，可以不分配，看实现

**4. 进程中虚拟页不同状态、OS不同缺页异常处理程序？**

- **未分配**：终止、段错误
- **按需分配**：虚拟页属于某个已分配的虚拟内存区域（vm_struct），分配物理页并映射
- **已映射**：nothing to do
- **换出**：执行换入操作，恢复进程执行


---
**思考题**：

- 1. 手推 Belady 异常
- 2. 换页还重要吗
- 3. SLAB 分配器进行物理内存分配、如何避免缓冲冲突？染色
- 4. OS 如何抵御 Rowhammer 和 Cache side channel


Rowhammer：尽管Memory controller屏蔽了物理内存细节， 但是真实访问依然会用到Row等物理结构
攻击者利用物理内存缺陷，极频繁访问某一行，其相邻行某些位会发生翻转

- 为抵御Rowhammer攻击，实际上操作系统需要知道 部分硬件细节，从而能够在物理内存分配时主动加入 一些Guard Page
- 为抵御cache Side Channel攻击，操作系统需要知 道同样cache映射细节
